# ğŸ“Š Netflix Customer Churn Prediction

## ğŸš€ Project Overview

Netflix, like many subscription-based platforms, faces the challenge of customer churn. Retaining existing customers is significantly more cost-effective than acquiring new ones. This project delivers a full-scale machine learning solution to predict customer churn using behavioral and subscription data, from ingestion to deployment via a FastAPI interface.

This repository presents a production-grade, explainable, and reproducible ML pipeline with CI/CD, experiment tracking (**MLflow**), data versioning (**DVC**), and containerized deployment using **Docker**.

---

## ğŸ¯ Problem Statement

Netflix seeks to proactively identify users likely to cancel their subscriptions. Predicting churn enables targeted interventions to retain users and minimize revenue loss.

> **Goal:** Build an ML classification model that predicts churn based on customer behavior and plan details.

---

## ğŸ“Œ Key Features Used

| Feature                    | Type        | Description                                    |
| -------------------------- | ----------- | ---------------------------------------------- |
| watch\_hours               | Numerical   | Total hours watched                            |
| last\_login\_days          | Numerical   | Days since last login                          |
| number\_of\_profiles       | Numerical   | Total profiles under the account               |
| avg\_watch\_time\_per\_day | Numerical   | Daily average watch time                       |
| subscription\_type         | Categorical | Subscription level: Basic, Standard, Premium   |
| payment\_method            | Categorical | Payment method: Credit Card, UPI, PayPal, etc. |
| churned                    | Target      | 1 = Churned, 0 = Not churned                   |

---

## ğŸ“Š Key EDA Insights

### ğŸ”¬ Feature Significance

| Feature                    | Test           | p-value | Significant? |
| -------------------------- | -------------- | ------- | ------------ |
| subscription\_type         | Chi-Square     | 0.0000  | âœ… Yes        |
| payment\_method            | Chi-Square     | 0.0000  | âœ… Yes        |
| number\_of\_profiles       | Chi-Square     | 0.0000  | âœ… Yes        |
| watch\_hours               | Mann-Whitney U | 0.0000  | âœ… Yes        |
| last\_login\_days          | Mann-Whitney U | 0.0000  | âœ… Yes        |
| avg\_watch\_time\_per\_day | Mann-Whitney U | 0.0000  | âœ… Yes        |
| age                        | Mann-Whitney U | 0.7803  | âŒ No         |
| gender, region, device     | Chi-Square     | > 0.3   | âŒ No         |

> âœ… These statistically significant features were included in the final model pipeline.

---

## ğŸ—ï¸ Project Architecture

```bash
netflix-churn-prediction/
â”œâ”€â”€ data/                     # Raw and processed data
â”œâ”€â”€ models/                   # Trained model binaries
â”œâ”€â”€ reports/                  # Classification reports & plots
â”œâ”€â”€ static/                   # CSS
â”œâ”€â”€ templates/                # HTML UI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_ingestion.py     # Load dataset
â”‚   â”œâ”€â”€ data_preprocessing.py # Pipeline for scaling & encoding
â”‚   â””â”€â”€ model_training.py     # ML training & evaluation
â”œâ”€â”€ main.py                   # FastAPI backend
â”œâ”€â”€ Dockerfile                # Containerization
â”œâ”€â”€ .dvc/                     # DVC for data version control
â”œâ”€â”€ .github/workflows/        # CI/CD GitHub Actions
â””â”€â”€ README.md
```

---

## âš™ï¸ End-to-End ML Workflow

### 1ï¸âƒ£ Data Ingestion

* Loads `.csv` into DataFrame
* Handles errors and logs shape/summary

### 2ï¸âƒ£ Preprocessing

* OneHotEncoding (categorical)
* StandardScaler (numerical)
* Uses `ColumnTransformer` for pipeline modularity

### 3ï¸âƒ£ Model Training

* Models: `RandomForest`, `GradientBoosting`, `SVC`
* `GridSearchCV` for hyperparameter tuning
* Model artifacts saved to `models/`
* ROC curves + classification reports saved to `reports/`

### 4ï¸âƒ£ MLflow Tracking âœ…

* Tracks experiment metadata, metrics, parameters
* Stores models and artifacts
* UI accessible at `localhost:5000`

---

## ğŸ§ª Model Performance

| Model             | Accuracy | F1 Score | ROC AUC (Test) | ROC AUC (CV) | Notes                         |
| ----------------- | -------- | -------- | -------------- | ------------ | ----------------------------- |
| Random Forest     | 0.99     | 0.99     | **0.9995**     | 0.9987       | âœ… Best overallã€13â€ sourceã€‘     |
| Gradient Boosting | 0.99     | 0.99     | 0.9989         | 0.9991       | Robust & efficientã€12â€ sourceã€‘ |
| SVC               | 0.93     | 0.93     | 0.9844         | 0.9822       | Lightweightã€14â€ sourceã€‘        |

---

## ğŸŒ FastAPI Deployment

### ğŸ”§ API Endpoints:

* `/`: HTML frontend form for manual input
* `/api/predict`: JSON-based API for programmatic inference

### ğŸ”Œ Model Used:

* Random Forest (best AUC + accuracy)
* Accepts form or JSON input
* Returns churn prediction + confidence

---

## ğŸ³ Docker Setup

```Dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

Run locally:

```bash
docker build -t netflix-churn .
docker run -p 8000:8000 netflix-churn
```

---

## ğŸ” CI/CD Pipeline (GitHub Actions)

### âœ… Stages:

1. **Test Phase**

   * Install dependencies
   * Run `pytest` on unit tests
   * Pull versioned data using `dvc pull`

2. **Build Phase**

   * Docker image build with `CACHEBUST` arg
   * Push to DockerHub using GitHub Secrets

3. **Deploy Phase**

   * SSH into EC2 instance
   * Stop, remove old container
   * Pull and launch updated Docker image

### ğŸ” GitHub Repository Secrets

| Name                    | Purpose                            |
| ----------------------- | ---------------------------------- |
| `AWS_ACCESS_KEY_ID`     | AWS auth for DVC S3                |
| `AWS_SECRET_ACCESS_KEY` | AWS auth for DVC S3                |
| `DOCKER_USERNAME`       | DockerHub username for push        |
| `DOCKER_PASSWORD`       | DockerHub password/token           |
| `EC2_HOST`              | Public IP/DNS of EC2 instance      |
| `EC2_USER`              | SSH user for EC2 login             |
| `EC2_SSH_KEY`           | Private SSH key for GitHub Actions |

---

## ğŸ§¬ Data Versioning with DVC

* Tracks raw and preprocessed data versions
* Uses `.dvc/config` to connect to **AWS S3** remote
* Run `dvc push` and `dvc pull` to sync across environments
* Ensures reproducibility in CI and local experiments

---

## ğŸ“Œ Business Value & Insights

* ğŸ§  **High-risk churn users** are linked to:

  * Low engagement (low watch hours)
  * Infrequent logins
  * Basic plans & non-card payments

* ğŸ“ˆ **Operational Benefits**:

  * Preemptive retention campaigns
  * Personalized offers to vulnerable users
  * Reduce marketing costs via targeted outreach

---

## âœ… Run Locally (No Docker)

```bash
git clone <repo_url>
cd netflix-churn-prediction
python src/model_training.py        # Train all models
uvicorn main:app --reload           # Launch API server
```

---

## ğŸ™Œ Author

* ğŸ‘¨â€ğŸ’» Katta Sai Pranav Reddy

---

## ğŸ“ Tech Stack

* **Python 3.10**
* **Scikit-learn**, **MLflow**, **DVC**, **FastAPI**, **Docker**
* **GitHub Actions**, **AWS EC2**, **S3 Remote Storage**
